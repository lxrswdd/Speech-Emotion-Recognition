{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import MidTermFeatures as aF\n",
    "from pyAudioAnalysis import audioTrainTest as aT\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_no_avg_3Dfeatures(path,mid_window=0.15,mid_step=0.15,short_window = 0.05,short_step=0.025,steps = 100):\n",
    "    features, class_names, file_names = aF.multiple_directory_3Dfeature_extraction_no_avg(path,mid_step,mid_step,short_window,short_step,steps)\n",
    "    feature_matrix, labels = aT.features_to_matrix(features)\n",
    "    return feature_matrix,labels,class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threeD_data_store(input,output_name):\n",
    "    # The 2nd and 3rd dimensional are folded.\n",
    "    reshaped_input = input.reshape(input.shape[0],-1)\n",
    "    np.savetxt(output_name, reshaped_input,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threeD_data_load(input,output,third_dimension_size):\n",
    "    loaded_data = np.loadtxt(input)\n",
    "    Restored_data = loaded_data.reshape(loaded_data.shape[0], loaded_data.shape[1] // third_dimension_size, third_dimension_size)\n",
    "    return Restored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = ['/home/test/Speech/Wang/dataset/Trainingsets/angry',\n",
    "                '/home/test/Speech/Wang/dataset/Trainingsets/happy'\n",
    "#                 '/home/test/Speech/Wang/dataset/Trainingsets/sad'\n",
    "                ]\n",
    "\n",
    "testing_path = ['/home/test/Speech/Wang/dataset/testsets/angry',\n",
    "                '/home/test/Speech/Wang/dataset/testsets/happy'\n",
    "#                 '/home/test/Speech/Wang/dataset/testsets/sad'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start multiple directory non averaged feature extraction in 3D dimension...\n",
      "The audio is too long so skip one\n",
      "extraction done for one directory\n",
      "The audio is too long so skip one\n",
      "The audio is too long so skip one\n",
      "extraction done for one directory\n",
      "Extraction Done...\n",
      "Start multiple directory non averaged feature extraction in 3D dimension...\n",
      "extraction done for one directory\n",
      "extraction done for one directory\n",
      "Extraction Done...\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,class_names=extract_no_avg_3Dfeatures(training_path)\n",
    "X_test,y_test,class_names=extract_no_avg_3Dfeatures(testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, len(training_path),dtype='float32')\n",
    "y_test = tf.keras.utils.to_categorical(y_test, len(testing_path),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of training set (652, 100, 136)\n",
      "The dimension of testing set (91, 100, 136)\n",
      "The dimentsion of y_train (652, 2)\n"
     ]
    }
   ],
   "source": [
    "print('The dimension of training set',X_train.shape)\n",
    "print('The dimension of testing set',X_test.shape)\n",
    "print('The dimentsion of y_train',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeD_data_store(X_train,'X_training.csv')\n",
    "np.savetxt('y_training.csv',y_train,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeD_data_store(X_test,'X_testing.csv')\n",
    "np.savetxt('y_testing.csv',y_test,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
