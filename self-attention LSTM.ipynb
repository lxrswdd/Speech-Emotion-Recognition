{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from LXRfunc import load_dataset,masked_normalization\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Embedding,Bidirectional,Masking,LSTM,BatchNormalization,Input\n",
    "from keras.layers.merge import dot\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.regularizers import l2,l1\n",
    "from sklearn.utils import class_weight\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load succeed\n",
      "There are  2 classes\n",
      "shape of X_train:  (4917, 50, 136)\n",
      "shape of X_test:  (707, 50, 136)\n",
      "shape of y_train:  (4917, 2)\n",
      "shape of y_test:  (707, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test,num_classes = load_dataset('/mnt/lxr/SER/X_training.csv','/mnt/lxr/SER/y_training.csv','/mnt/lxr/SER/X_testing.csv','/mnt/lxr/SER/y_testing.csv',steps,0,136,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/privacy/.pyenv/versions/3.8.0/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.75607143, 0.69903327])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ints = [y.argmax() for y in y_train]\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_ints),y_ints)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train,scaled_X_test = masked_normalization(X_train,X_test,scaler='ss')\n",
    "X_train = scaled_X_train\n",
    "X_test = scaled_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_dimension = 100\n",
    "# scaled_X_train = np.reshape(scaled_X_train,(-1,scaled_X_train.shape[2]))\n",
    "# scaled_X_test = np.reshape(scaled_X_test,(-1,scaled_X_test.shape[2]))\n",
    "# pca = PCA(n_components = reduced_dimension)\n",
    "# pca.fit(scaled_X_train)\n",
    "# scaled_X_train = pca.transform(scaled_X_train)\n",
    "# scaled_X_test = pca.transform(scaled_X_test)\n",
    "# X_train  = np.reshape(scaled_X_train,(X_train.shape[0],X_train.shape[1],reduced_dimension))\n",
    "# X_test  = np.reshape(scaled_X_test,(X_test.shape[0],X_test.shape[1],reduced_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def opt_select(optimizer,learning_rate):\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        adamopt = tf.keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "        return adamopt\n",
    "    \n",
    "    elif optimizer == 'SGD':\n",
    "        \n",
    "        SGDopt = tf.keras.optimizers.SGD(lr=learning_rate)\n",
    "        return SGDopt\n",
    "    \n",
    "    elif optimizer == 'RMS':\n",
    "        \n",
    "        RMSopt = tf.keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-6)\n",
    "        return RMSopt\n",
    "    \n",
    "    else:\n",
    "        print('undefined optimizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def attention_model(X_train, y_train, X_val, y_val,X_test,num_classes,dropout=0.2, batch_size=68, learning_rate=0.0001,epochs=20,optimizer='Adam'):\n",
    "    \n",
    "    Dense_unit = 6\n",
    "    LSTM_unit = 6\n",
    "    \n",
    "    dense_reg = 0.003\n",
    "    attention_param = LSTM_unit*2\n",
    "    attention_init_value = 1.0/attention_param\n",
    "    \n",
    "    \n",
    "    u_train = np.full((X_train.shape[0], attention_param),\n",
    "                      attention_init_value, dtype=np.float32)\n",
    "    u_val = np.full((X_val.shape[0],attention_param),\n",
    "                     attention_init_value, dtype=np.float32)\n",
    "    u_test = np.full((X_test.shape[0],attention_param),\n",
    "                     attention_init_value, dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    with keras.backend.name_scope('BLSTMLayer'):\n",
    "        # Bi-directional Long Short-Term Memory for learning the temporal aggregation\n",
    "        input_feature = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
    "        x = Masking(mask_value=0)(input_feature)\n",
    "        \n",
    "#         x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Dense(136,kernel_regularizer=l2(dense_reg),activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(25,kernel_regularizer=l2(dense_reg),activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(20,kernel_regularizer=l2(dense_reg),activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "#         x = Dense(10,kernel_regularizer=l2(dense_reg),activation='relu')(x)\n",
    "#         x = Dropout(dropout)(x)\n",
    "\n",
    "\n",
    "        y = Bidirectional(LSTM(LSTM_unit,activity_regularizer=l2(0.0029),kernel_regularizer=l2(0.002),recurrent_regularizer=l2(0.002),return_sequences=True, dropout=dropout))(x)\n",
    "        y = Bidirectional(LSTM(LSTM_unit,return_sequences=True, dropout=dropout))(y)\n",
    "        y = Bidirectional(LSTM(LSTM_unit,activity_regularizer=l2(0.0029),kernel_regularizer=l2(0.002),recurrent_regularizer=l2(0.002),return_sequences=True, dropout=dropout))(y)\n",
    "\n",
    "\n",
    "    with keras.backend.name_scope('AttentionLayer'):\n",
    "        # Logistic regression for learning the attention parameters with a standalone feature as input\n",
    "        input_attention = Input(shape=(LSTM_unit * 2,))\n",
    "        u = Dense(LSTM_unit * 2, activation='softmax')(input_attention)\n",
    "\n",
    "        # To compute the final weights for the frames which sum to unity\n",
    "        alpha = dot([u, y], axes=-1)  # inner prod.\n",
    "        alpha = Activation('softmax')(alpha)\n",
    "\n",
    "    with keras.backend.name_scope('WeightedPooling'):\n",
    "        # Weighted pooling to get the utterance-level representation\n",
    "        z = dot([alpha, y], axes=1)\n",
    "\n",
    "    # Get posterior probability for each emotional class\n",
    "    output = Dense(num_classes, activation='softmax')(z)\n",
    "\n",
    "    model = Model(inputs=[input_attention, input_feature], outputs=output)\n",
    "#     model2 = Model(inputs=[input_attention, input_feature], outputs=model.get_layer('masking')).output\n",
    "#     print(model2.predict(X_test))\n",
    "    \n",
    "    optimizer = opt_select(optimizer,learning_rate)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "    \n",
    "    print(model.summary())\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=200, verbose=0, mode='min'),\n",
    "                 ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')]\n",
    "    \n",
    "    hist = model.fit([u_train, X_train], \n",
    "                     y_train, \n",
    "                     shuffle=False,\n",
    "                     batch_size=batch_size, \n",
    "                     epochs=epochs, \n",
    "                     callbacks=callbacks,\n",
    "                     class_weight = {0:1.75607143,1: 0.69903327},\n",
    "                     validation_data=([u_val, X_val], y_val)\n",
    "                    )\n",
    "    \n",
    "    model.load_weights(filepath = '.mdl_wts.hdf5')\n",
    "    model.save('/mnt/lxr/SER/trained_models/Neutral.h5')\n",
    "    \n",
    "    y_pred = model.predict([u_test,X_test])\n",
    "    \n",
    "#    1.75607143, 0.69903327\n",
    "# 2.76971831, 0.61014583 4.33597884, 0.56517241\n",
    "#     kernel_regularizer=l2(0.002),recurrent_regularizer=l2(0.002),\n",
    "\n",
    "    return hist,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size= 256\n",
    "\n",
    "#217\n",
    "epochs = 300\n",
    "lr = 0.0007\n",
    "\n",
    "optimizer = 'RMS'\n",
    "num_classes = y_train.shape[1]\n",
    "dropout=0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50, 136)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 50, 136)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 136)      18632       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 136)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50, 25)       3425        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 25)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50, 20)       520         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 20)       0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 12)       1296        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 12)       912         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 12)           156         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 50, 12)       912         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 50)           0           dense_3[0][0]                    \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 50)           0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 12)           0           activation[0][0]                 \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            26          dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 25,879\n",
      "Trainable params: 25,879\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 7s 447ms/step - loss: 1.4504 - accuracy: 0.5708 - val_loss: 1.3517 - val_accuracy: 0.2998\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 1.3070 - accuracy: 0.5034 - val_loss: 1.2502 - val_accuracy: 0.3089\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 1.2082 - accuracy: 0.5052 - val_loss: 1.1654 - val_accuracy: 0.3709\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 1.1249 - accuracy: 0.5584 - val_loss: 1.0914 - val_accuracy: 0.5213\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 1.0531 - accuracy: 0.6143 - val_loss: 1.0253 - val_accuracy: 0.6067\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.9949 - accuracy: 0.6339 - val_loss: 0.9771 - val_accuracy: 0.6301\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.9475 - accuracy: 0.6479 - val_loss: 0.9359 - val_accuracy: 0.6423\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.9102 - accuracy: 0.6585 - val_loss: 0.8867 - val_accuracy: 0.6717\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.8858 - accuracy: 0.6529 - val_loss: 0.8753 - val_accuracy: 0.6596\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.8586 - accuracy: 0.6606 - val_loss: 0.8645 - val_accuracy: 0.6423\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.8365 - accuracy: 0.6613 - val_loss: 0.8512 - val_accuracy: 0.6372\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.8182 - accuracy: 0.6702 - val_loss: 0.8232 - val_accuracy: 0.6413\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.7963 - accuracy: 0.6692 - val_loss: 0.8123 - val_accuracy: 0.6494\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.7813 - accuracy: 0.6679 - val_loss: 0.8061 - val_accuracy: 0.6362\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.7704 - accuracy: 0.6644 - val_loss: 0.7874 - val_accuracy: 0.6606\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.7525 - accuracy: 0.6799 - val_loss: 0.7986 - val_accuracy: 0.6250\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.7420 - accuracy: 0.6745 - val_loss: 0.7733 - val_accuracy: 0.6352\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.7283 - accuracy: 0.6771 - val_loss: 0.7734 - val_accuracy: 0.6372\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.7197 - accuracy: 0.6860 - val_loss: 0.7175 - val_accuracy: 0.6911\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.7141 - accuracy: 0.6850 - val_loss: 0.7303 - val_accuracy: 0.6657\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.7056 - accuracy: 0.6817 - val_loss: 0.7762 - val_accuracy: 0.6077\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.6981 - accuracy: 0.6903 - val_loss: 0.7071 - val_accuracy: 0.6758\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.6904 - accuracy: 0.6880 - val_loss: 0.7421 - val_accuracy: 0.6321\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.6798 - accuracy: 0.6954 - val_loss: 0.7222 - val_accuracy: 0.6606\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.6766 - accuracy: 0.6908 - val_loss: 0.7362 - val_accuracy: 0.6341\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.6716 - accuracy: 0.6860 - val_loss: 0.7077 - val_accuracy: 0.6575\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.6637 - accuracy: 0.6982 - val_loss: 0.7903 - val_accuracy: 0.5722\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.6609 - accuracy: 0.6954 - val_loss: 0.7422 - val_accuracy: 0.6220\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.6579 - accuracy: 0.6957 - val_loss: 0.7123 - val_accuracy: 0.6545\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.6552 - accuracy: 0.7000 - val_loss: 0.6781 - val_accuracy: 0.6911\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.6515 - accuracy: 0.7005 - val_loss: 0.7566 - val_accuracy: 0.5945\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.6479 - accuracy: 0.7053 - val_loss: 0.6715 - val_accuracy: 0.6860\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.6450 - accuracy: 0.7012 - val_loss: 0.7716 - val_accuracy: 0.6037\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.6404 - accuracy: 0.7109 - val_loss: 0.7250 - val_accuracy: 0.6291\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.6379 - accuracy: 0.7119 - val_loss: 0.6928 - val_accuracy: 0.6555\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.6321 - accuracy: 0.7168 - val_loss: 0.6676 - val_accuracy: 0.6900\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.6284 - accuracy: 0.7137 - val_loss: 0.6597 - val_accuracy: 0.7053\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.6375 - accuracy: 0.7086 - val_loss: 0.6472 - val_accuracy: 0.7124\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.6197 - accuracy: 0.7290 - val_loss: 0.6787 - val_accuracy: 0.6789\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.6233 - accuracy: 0.7180 - val_loss: 0.7852 - val_accuracy: 0.5925\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.6286 - accuracy: 0.7068 - val_loss: 0.6950 - val_accuracy: 0.6606\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.6172 - accuracy: 0.7196 - val_loss: 0.7024 - val_accuracy: 0.6565\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.6226 - accuracy: 0.7218 - val_loss: 0.6813 - val_accuracy: 0.6748\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.6125 - accuracy: 0.7231 - val_loss: 0.7495 - val_accuracy: 0.6179\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.6180 - accuracy: 0.7152 - val_loss: 0.6394 - val_accuracy: 0.7154\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.6060 - accuracy: 0.7305 - val_loss: 0.6473 - val_accuracy: 0.7104\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.6060 - accuracy: 0.7285 - val_loss: 0.6425 - val_accuracy: 0.7124\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.6046 - accuracy: 0.7338 - val_loss: 0.6419 - val_accuracy: 0.7033\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.6046 - accuracy: 0.7302 - val_loss: 0.6775 - val_accuracy: 0.6789\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.6003 - accuracy: 0.7310 - val_loss: 0.7077 - val_accuracy: 0.6545\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.6028 - accuracy: 0.7310 - val_loss: 0.7103 - val_accuracy: 0.6474\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.5897 - accuracy: 0.7346 - val_loss: 0.7521 - val_accuracy: 0.6098\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.6024 - accuracy: 0.7305 - val_loss: 0.6843 - val_accuracy: 0.6707\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5951 - accuracy: 0.7391 - val_loss: 0.6679 - val_accuracy: 0.6799\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5995 - accuracy: 0.7295 - val_loss: 0.7147 - val_accuracy: 0.6362\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5917 - accuracy: 0.7368 - val_loss: 0.7058 - val_accuracy: 0.6626\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5830 - accuracy: 0.7480 - val_loss: 0.6847 - val_accuracy: 0.6728\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5914 - accuracy: 0.7323 - val_loss: 0.6816 - val_accuracy: 0.6697\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5840 - accuracy: 0.7422 - val_loss: 0.7139 - val_accuracy: 0.6423\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5871 - accuracy: 0.7442 - val_loss: 0.6843 - val_accuracy: 0.6677\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5908 - accuracy: 0.7381 - val_loss: 0.6908 - val_accuracy: 0.6707\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5875 - accuracy: 0.7323 - val_loss: 0.7946 - val_accuracy: 0.5935\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5761 - accuracy: 0.7524 - val_loss: 0.6557 - val_accuracy: 0.6961\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5700 - accuracy: 0.7567 - val_loss: 0.8131 - val_accuracy: 0.5742\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5826 - accuracy: 0.7419 - val_loss: 0.6567 - val_accuracy: 0.6961\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5794 - accuracy: 0.7424 - val_loss: 0.7063 - val_accuracy: 0.6687\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5611 - accuracy: 0.7671 - val_loss: 0.6791 - val_accuracy: 0.6728\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5729 - accuracy: 0.7551 - val_loss: 0.6684 - val_accuracy: 0.6839\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5692 - accuracy: 0.7470 - val_loss: 0.7107 - val_accuracy: 0.6555\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.5623 - accuracy: 0.7615 - val_loss: 0.6611 - val_accuracy: 0.6921\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5693 - accuracy: 0.7557 - val_loss: 0.7416 - val_accuracy: 0.6321\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5710 - accuracy: 0.7455 - val_loss: 0.6530 - val_accuracy: 0.6911\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5660 - accuracy: 0.7597 - val_loss: 0.6969 - val_accuracy: 0.6555\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5654 - accuracy: 0.7610 - val_loss: 0.6682 - val_accuracy: 0.6809\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5651 - accuracy: 0.7610 - val_loss: 0.7393 - val_accuracy: 0.6372\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.5581 - accuracy: 0.7516 - val_loss: 0.7030 - val_accuracy: 0.6565\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5567 - accuracy: 0.7577 - val_loss: 0.8599 - val_accuracy: 0.5742\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.5680 - accuracy: 0.7544 - val_loss: 0.6652 - val_accuracy: 0.6951\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5469 - accuracy: 0.7755 - val_loss: 0.7311 - val_accuracy: 0.6565\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5515 - accuracy: 0.7630 - val_loss: 0.7120 - val_accuracy: 0.6494\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.5490 - accuracy: 0.7740 - val_loss: 0.7213 - val_accuracy: 0.6575\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.5483 - accuracy: 0.7735 - val_loss: 0.7096 - val_accuracy: 0.6626\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5468 - accuracy: 0.7737 - val_loss: 0.7725 - val_accuracy: 0.6372\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5437 - accuracy: 0.7735 - val_loss: 0.6825 - val_accuracy: 0.6758\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5524 - accuracy: 0.7658 - val_loss: 0.6957 - val_accuracy: 0.6646\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5445 - accuracy: 0.7684 - val_loss: 0.7019 - val_accuracy: 0.6687\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5322 - accuracy: 0.7818 - val_loss: 0.7215 - val_accuracy: 0.6616\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5386 - accuracy: 0.7729 - val_loss: 0.7319 - val_accuracy: 0.6524\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.5404 - accuracy: 0.7735 - val_loss: 0.8363 - val_accuracy: 0.5752\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.5288 - accuracy: 0.7752 - val_loss: 0.7557 - val_accuracy: 0.6362\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5378 - accuracy: 0.7801 - val_loss: 0.7441 - val_accuracy: 0.6504\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.5296 - accuracy: 0.7793 - val_loss: 0.7920 - val_accuracy: 0.6189\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5312 - accuracy: 0.7824 - val_loss: 0.7409 - val_accuracy: 0.6535\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.5368 - accuracy: 0.7811 - val_loss: 0.7158 - val_accuracy: 0.6585\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5330 - accuracy: 0.7788 - val_loss: 0.7015 - val_accuracy: 0.6707\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5252 - accuracy: 0.7821 - val_loss: 0.7041 - val_accuracy: 0.6677\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5281 - accuracy: 0.7829 - val_loss: 0.9596 - val_accuracy: 0.5498\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5299 - accuracy: 0.7824 - val_loss: 0.8104 - val_accuracy: 0.6138\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5365 - accuracy: 0.7798 - val_loss: 0.7109 - val_accuracy: 0.6738\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5222 - accuracy: 0.7905 - val_loss: 0.7352 - val_accuracy: 0.6575\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5148 - accuracy: 0.7869 - val_loss: 0.7203 - val_accuracy: 0.6616\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.5203 - accuracy: 0.7857 - val_loss: 0.7558 - val_accuracy: 0.6463\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5228 - accuracy: 0.7872 - val_loss: 0.7110 - val_accuracy: 0.6789\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5231 - accuracy: 0.7913 - val_loss: 0.7201 - val_accuracy: 0.6606\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5141 - accuracy: 0.7918 - val_loss: 0.7265 - val_accuracy: 0.6697\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5111 - accuracy: 0.7976 - val_loss: 0.7529 - val_accuracy: 0.6514\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5240 - accuracy: 0.7900 - val_loss: 0.7237 - val_accuracy: 0.6484\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5075 - accuracy: 0.7958 - val_loss: 0.8380 - val_accuracy: 0.5955\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.5127 - accuracy: 0.7918 - val_loss: 0.7504 - val_accuracy: 0.6392\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.5146 - accuracy: 0.7938 - val_loss: 0.7484 - val_accuracy: 0.6504\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.5120 - accuracy: 0.7963 - val_loss: 0.7235 - val_accuracy: 0.6657\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5034 - accuracy: 0.7994 - val_loss: 0.7268 - val_accuracy: 0.6585\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4992 - accuracy: 0.8012 - val_loss: 0.7351 - val_accuracy: 0.6596\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.4749 - accuracy: 0.8182 - val_loss: 0.7352 - val_accuracy: 0.7073\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.5108 - accuracy: 0.8017 - val_loss: 0.7271 - val_accuracy: 0.6778\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.5057 - accuracy: 0.8052 - val_loss: 0.8503 - val_accuracy: 0.6220\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.4949 - accuracy: 0.8050 - val_loss: 0.7189 - val_accuracy: 0.6778\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.5094 - accuracy: 0.7989 - val_loss: 0.7678 - val_accuracy: 0.6484\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4909 - accuracy: 0.8088 - val_loss: 0.7594 - val_accuracy: 0.6565\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4886 - accuracy: 0.8141 - val_loss: 0.7182 - val_accuracy: 0.6850\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.5033 - accuracy: 0.8027 - val_loss: 0.7020 - val_accuracy: 0.6992\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4998 - accuracy: 0.8108 - val_loss: 0.7569 - val_accuracy: 0.6596\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4986 - accuracy: 0.8075 - val_loss: 0.7202 - val_accuracy: 0.6646\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4690 - accuracy: 0.8195 - val_loss: 0.7503 - val_accuracy: 0.6646\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.5075 - accuracy: 0.8093 - val_loss: 0.8280 - val_accuracy: 0.6270\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4854 - accuracy: 0.8157 - val_loss: 0.7490 - val_accuracy: 0.6687\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.4842 - accuracy: 0.8169 - val_loss: 0.7477 - val_accuracy: 0.6768\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4985 - accuracy: 0.8116 - val_loss: 0.7556 - val_accuracy: 0.6616\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4868 - accuracy: 0.8205 - val_loss: 0.7319 - val_accuracy: 0.6789\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.4741 - accuracy: 0.8220 - val_loss: 0.7988 - val_accuracy: 0.6433\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.4739 - accuracy: 0.8213 - val_loss: 0.8290 - val_accuracy: 0.6128\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.4909 - accuracy: 0.8126 - val_loss: 0.7367 - val_accuracy: 0.6799\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4628 - accuracy: 0.8322 - val_loss: 0.7357 - val_accuracy: 0.6728\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4848 - accuracy: 0.8098 - val_loss: 0.7977 - val_accuracy: 0.6413\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4832 - accuracy: 0.8167 - val_loss: 0.8427 - val_accuracy: 0.6260\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4870 - accuracy: 0.8205 - val_loss: 0.7552 - val_accuracy: 0.6687\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.4769 - accuracy: 0.8258 - val_loss: 0.7722 - val_accuracy: 0.6606\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4655 - accuracy: 0.8289 - val_loss: 0.7541 - val_accuracy: 0.6616\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.4689 - accuracy: 0.8317 - val_loss: 0.7425 - val_accuracy: 0.6768\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4619 - accuracy: 0.8324 - val_loss: 0.8543 - val_accuracy: 0.6382\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4749 - accuracy: 0.8230 - val_loss: 0.8004 - val_accuracy: 0.6413\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4615 - accuracy: 0.8274 - val_loss: 0.7886 - val_accuracy: 0.6535\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4470 - accuracy: 0.8449 - val_loss: 1.2201 - val_accuracy: 0.5376\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4806 - accuracy: 0.8180 - val_loss: 0.7428 - val_accuracy: 0.6900\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4577 - accuracy: 0.8352 - val_loss: 0.7710 - val_accuracy: 0.6758\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.4692 - accuracy: 0.8284 - val_loss: 0.7638 - val_accuracy: 0.6748\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.4552 - accuracy: 0.8294 - val_loss: 0.7972 - val_accuracy: 0.6657\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4724 - accuracy: 0.8279 - val_loss: 0.8108 - val_accuracy: 0.6372\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4833 - accuracy: 0.8258 - val_loss: 0.7601 - val_accuracy: 0.6697\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4460 - accuracy: 0.8429 - val_loss: 0.8702 - val_accuracy: 0.6331\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4580 - accuracy: 0.8314 - val_loss: 0.7442 - val_accuracy: 0.6829\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4624 - accuracy: 0.8319 - val_loss: 0.7669 - val_accuracy: 0.6768\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4580 - accuracy: 0.8406 - val_loss: 0.8108 - val_accuracy: 0.6514\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4533 - accuracy: 0.8375 - val_loss: 0.7675 - val_accuracy: 0.6646\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4491 - accuracy: 0.8398 - val_loss: 0.7746 - val_accuracy: 0.6626\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4475 - accuracy: 0.8474 - val_loss: 0.7689 - val_accuracy: 0.6829\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4570 - accuracy: 0.8350 - val_loss: 0.7549 - val_accuracy: 0.6738\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4293 - accuracy: 0.8515 - val_loss: 0.7669 - val_accuracy: 0.6931\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4514 - accuracy: 0.8431 - val_loss: 0.9620 - val_accuracy: 0.6077\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4466 - accuracy: 0.8370 - val_loss: 0.8045 - val_accuracy: 0.6707\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4663 - accuracy: 0.8340 - val_loss: 0.8823 - val_accuracy: 0.6189\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.4653 - accuracy: 0.8261 - val_loss: 0.7182 - val_accuracy: 0.6850\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4470 - accuracy: 0.8457 - val_loss: 0.7741 - val_accuracy: 0.6626\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4483 - accuracy: 0.8411 - val_loss: 0.7641 - val_accuracy: 0.6687\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.4467 - accuracy: 0.8459 - val_loss: 0.7735 - val_accuracy: 0.6626\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4414 - accuracy: 0.8449 - val_loss: 0.7767 - val_accuracy: 0.6982\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4495 - accuracy: 0.8426 - val_loss: 0.7725 - val_accuracy: 0.6758\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4359 - accuracy: 0.8533 - val_loss: 0.9528 - val_accuracy: 0.6209\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4452 - accuracy: 0.8434 - val_loss: 0.8088 - val_accuracy: 0.6545\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.4258 - accuracy: 0.8607 - val_loss: 0.8007 - val_accuracy: 0.6596\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4293 - accuracy: 0.8541 - val_loss: 0.7495 - val_accuracy: 0.6758\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4164 - accuracy: 0.8640 - val_loss: 0.8276 - val_accuracy: 0.6646\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4412 - accuracy: 0.8513 - val_loss: 0.9431 - val_accuracy: 0.6260\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4477 - accuracy: 0.8459 - val_loss: 0.7684 - val_accuracy: 0.6799\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4282 - accuracy: 0.8566 - val_loss: 0.8166 - val_accuracy: 0.6524\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4361 - accuracy: 0.8513 - val_loss: 0.8089 - val_accuracy: 0.6402\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4405 - accuracy: 0.8508 - val_loss: 0.7870 - val_accuracy: 0.6707\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4185 - accuracy: 0.8622 - val_loss: 0.8500 - val_accuracy: 0.6565\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4179 - accuracy: 0.8688 - val_loss: 0.8705 - val_accuracy: 0.6524\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4392 - accuracy: 0.8523 - val_loss: 0.8278 - val_accuracy: 0.6352\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.4220 - accuracy: 0.8581 - val_loss: 0.8009 - val_accuracy: 0.6616\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.4176 - accuracy: 0.8622 - val_loss: 0.8147 - val_accuracy: 0.6667\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4232 - accuracy: 0.8594 - val_loss: 0.7924 - val_accuracy: 0.6809\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.4516 - accuracy: 0.8413 - val_loss: 0.7696 - val_accuracy: 0.6717\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.3975 - accuracy: 0.8711 - val_loss: 0.8049 - val_accuracy: 0.6870\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.4111 - accuracy: 0.8645 - val_loss: 0.7962 - val_accuracy: 0.6850\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4184 - accuracy: 0.8696 - val_loss: 0.8127 - val_accuracy: 0.6728\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3989 - accuracy: 0.8749 - val_loss: 0.8359 - val_accuracy: 0.6829\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4076 - accuracy: 0.8663 - val_loss: 1.0222 - val_accuracy: 0.6189\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.4251 - accuracy: 0.8655 - val_loss: 0.8256 - val_accuracy: 0.6758\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4135 - accuracy: 0.8632 - val_loss: 0.8416 - val_accuracy: 0.6667\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4291 - accuracy: 0.8619 - val_loss: 0.7977 - val_accuracy: 0.6535\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4020 - accuracy: 0.8701 - val_loss: 0.8029 - val_accuracy: 0.6717\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4091 - accuracy: 0.8688 - val_loss: 0.8300 - val_accuracy: 0.6657\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4272 - accuracy: 0.8655 - val_loss: 0.8085 - val_accuracy: 0.6585\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4121 - accuracy: 0.8713 - val_loss: 0.8072 - val_accuracy: 0.6717\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4013 - accuracy: 0.8670 - val_loss: 0.8552 - val_accuracy: 0.6545\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4147 - accuracy: 0.8604 - val_loss: 0.8547 - val_accuracy: 0.6626\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4357 - accuracy: 0.8546 - val_loss: 0.7754 - val_accuracy: 0.6778\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.3992 - accuracy: 0.8731 - val_loss: 0.8191 - val_accuracy: 0.6697\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.4100 - accuracy: 0.8721 - val_loss: 0.8971 - val_accuracy: 0.6260\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3895 - accuracy: 0.8744 - val_loss: 0.8543 - val_accuracy: 0.6646\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4079 - accuracy: 0.8663 - val_loss: 0.8339 - val_accuracy: 0.6758\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.4092 - accuracy: 0.8635 - val_loss: 0.7918 - val_accuracy: 0.6728\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3840 - accuracy: 0.8810 - val_loss: 0.8092 - val_accuracy: 0.6809\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4269 - accuracy: 0.8660 - val_loss: 0.8489 - val_accuracy: 0.6707\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3902 - accuracy: 0.8787 - val_loss: 0.8072 - val_accuracy: 0.6839\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.4144 - accuracy: 0.8622 - val_loss: 0.8111 - val_accuracy: 0.6748\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3964 - accuracy: 0.8706 - val_loss: 0.7826 - val_accuracy: 0.6809\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4037 - accuracy: 0.8726 - val_loss: 0.8371 - val_accuracy: 0.6646\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.3767 - accuracy: 0.8802 - val_loss: 0.8584 - val_accuracy: 0.6931\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4104 - accuracy: 0.8632 - val_loss: 0.8251 - val_accuracy: 0.6778\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4126 - accuracy: 0.8696 - val_loss: 0.8580 - val_accuracy: 0.6565\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4045 - accuracy: 0.8713 - val_loss: 0.7656 - val_accuracy: 0.7002\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.3518 - accuracy: 0.8965 - val_loss: 0.8726 - val_accuracy: 0.6931\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4106 - accuracy: 0.8711 - val_loss: 0.8926 - val_accuracy: 0.6514\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3749 - accuracy: 0.8876 - val_loss: 0.8388 - val_accuracy: 0.6972\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4156 - accuracy: 0.8650 - val_loss: 0.8380 - val_accuracy: 0.6626\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3864 - accuracy: 0.8734 - val_loss: 0.8069 - val_accuracy: 0.6900\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.4068 - accuracy: 0.8688 - val_loss: 0.8996 - val_accuracy: 0.6514\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3878 - accuracy: 0.8805 - val_loss: 0.7928 - val_accuracy: 0.6839\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3804 - accuracy: 0.8881 - val_loss: 0.8665 - val_accuracy: 0.6728\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.4040 - accuracy: 0.8668 - val_loss: 0.8034 - val_accuracy: 0.6900\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.4008 - accuracy: 0.8792 - val_loss: 0.8082 - val_accuracy: 0.6839\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4002 - accuracy: 0.8719 - val_loss: 0.8506 - val_accuracy: 0.6514\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3939 - accuracy: 0.8800 - val_loss: 0.8489 - val_accuracy: 0.6799\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.3726 - accuracy: 0.8889 - val_loss: 0.9746 - val_accuracy: 0.6291\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3955 - accuracy: 0.8767 - val_loss: 0.8777 - val_accuracy: 0.6484\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3957 - accuracy: 0.8767 - val_loss: 0.9639 - val_accuracy: 0.6169\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.3887 - accuracy: 0.8792 - val_loss: 0.8352 - val_accuracy: 0.6890\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4065 - accuracy: 0.8734 - val_loss: 0.8664 - val_accuracy: 0.6575\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.3876 - accuracy: 0.8795 - val_loss: 0.8808 - val_accuracy: 0.6565\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3869 - accuracy: 0.8830 - val_loss: 0.8381 - val_accuracy: 0.6728\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.3720 - accuracy: 0.8899 - val_loss: 0.9764 - val_accuracy: 0.6484\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.3920 - accuracy: 0.8800 - val_loss: 0.8626 - val_accuracy: 0.6717\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.3551 - accuracy: 0.8963 - val_loss: 0.9204 - val_accuracy: 0.6717\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.4027 - accuracy: 0.8764 - val_loss: 0.8283 - val_accuracy: 0.6768\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3923 - accuracy: 0.8759 - val_loss: 0.8697 - val_accuracy: 0.6626\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.3821 - accuracy: 0.8841 - val_loss: 0.8496 - val_accuracy: 0.6728\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.3841 - accuracy: 0.8808 - val_loss: 0.8553 - val_accuracy: 0.6636\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.3624 - accuracy: 0.8919 - val_loss: 0.9771 - val_accuracy: 0.6504\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.4077 - accuracy: 0.8698 - val_loss: 0.7900 - val_accuracy: 0.6809\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.3731 - accuracy: 0.8930 - val_loss: 0.8776 - val_accuracy: 0.6657\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.3712 - accuracy: 0.8902 - val_loss: 0.8412 - val_accuracy: 0.6728\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.3851 - accuracy: 0.8813 - val_loss: 0.8874 - val_accuracy: 0.6524\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(6)\n",
    "history,y_pred = attention_model(X_train, y_train, X_val, y_val,X_test, num_classes,dropout = dropout,batch_size=batch_size, learning_rate=lr,epochs=epochs,optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min loss  0.6393598318099976\n",
      "highest acc 0.7154471278190613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 432x288 with 1 Axes>,\n",
       " <AxesSubplot:xlabel='predicted label', ylabel='true label'>)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x2448 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_length = 0\n",
    "fig = plt.figure(figsize=(14, 34))\n",
    " \n",
    "ax = fig.add_subplot(10,2,1)\n",
    "ax.plot(history.history['accuracy'])\n",
    "ax.plot(history.history['val_accuracy'])\n",
    "plt.hlines(0.75,300,line_length,'g')\n",
    "\n",
    "title = 'acc'\n",
    "ax.title.set_text(title)\n",
    "\n",
    "ax = fig.add_subplot(10,2,3)\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "plt.hlines(0.6,600,line_length,'g')\n",
    "\n",
    "title = 'loss'\n",
    "ax.title.set_text(title)\n",
    "\n",
    "min_loss = min(history.history['val_loss'])\n",
    "min_index = history.history['val_loss'].index(min_loss)\n",
    "highest_acc = history.history['val_accuracy'][min_index]\n",
    "print('min loss ',min_loss)\n",
    "print('highest acc',highest_acc)\n",
    "\n",
    "mat = confusion_matrix(y_test.argmax(axis=1),y_pred.argmax(axis=1))\n",
    "plot_confusion_matrix(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.66      0.54       200\n",
      "           1       0.84      0.70      0.76       507\n",
      "\n",
      "    accuracy                           0.68       707\n",
      "   macro avg       0.65      0.68      0.65       707\n",
      "weighted avg       0.73      0.68      0.70       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_param = 3*2\n",
    "# attention_init_value = 1.0/attention_param\n",
    "# u_test = np.full((X_test.shape[0],attention_param),\n",
    "#                      attention_init_value, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.evaluate([u_test,X_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
